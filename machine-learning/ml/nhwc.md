# NHWC

ì´ì „ê¹Œì§€ëŠ” 1ì°¨ì› dataë¥¼ ê°€ì§€ê³  ê¸°ê³„í•™ìŠµì„ í–ˆì—ˆë‹¤ë©´ ì´ì œë¶€í„°ëŠ” **Nì°¨ì› data**ë¥¼ ê°€ì§€ê³  í•™ìŠµì„ í•´ë³´ë ¤ê³  í•œë‹¤.

Nì°¨ì› ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê¸°ì— ì•ì„œì„œ ì•Œì•„ë‘¬ì•¼í•  ê°œë…ë“¤ì´ ìˆëŠ”ë° ì•„ë˜ì„œ ì„¤ëª…í•˜ê² ë‹¤.

### ğŸ¤” What is NHWC?

* **N** : a number of sample \#ìƒ˜í”Œ 
* **H** : height \#ë†’ì´
* **w** : width \#ë„ˆë¹„
* **C** : a number of channel \#ì±„ë„ ìˆ˜

### ì‹¤



```text
import tensorflow as tf
import numpy as np
import random

tf.random.set_random_seed(0)
np.random.seed(0)
random.seed(0)

from tensorflow.examples.tutorials.mnist import input_data

#784 data -> img

mnist = input_data.read_data_sets('MINST_DATA/', one_hot=True)
nb_classes = 10

X = tf.compat.v1.placeholder(tf.float32, shape = [None, 784])#28 * 28=784
Y= tf.compat.v1.placeholder(tf.float32, shape = [None, nb_classes])#TensorShape([Dimension(None), Dimension(10)])



X_img = tf.reshape(X, shape =[-1, 28, 28, 1])#NHWC
#TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)])
w1 = tf.compat.v1.get_variable('w1', shape = [3, 3, 1, 32], #HWCN   3x3 filter  weight name, filtershape, filterìˆ˜:32ê°œ, initial value
                               initializer=tf.contrib.layers.xavier_initializer())#hw -> odd. so, 3x3 ì‚¬ìš©. chanelìˆ˜ -> 2ì§„ìˆ˜ ì‚¬ìš©(8,16, 32, 64, 128, ...)
L1 = tf.nn.conv2d(X_img, w1, strides=[1,1], padding='SAME')#hì™€wê°€ ë³€ê²½ë˜ì§€ ì•Šê²Œ paddì„ ì£¼ë ¤ê³ . strideëŠ” ëŒ€ì²´ì ìœ¼ë¡œ h, wë§Œ ì •í•´ì¤Œ
#L1's shape = [None, 28, 28, 32]
L1 = tf.nn.relu(L1)
```

**NHWC** X **HWCN** =&gt; **NHWC**\(=chanel\)

HWCN ì—¬ê¸°ì˜ ì±„ë„ ìˆ˜\(c\) =  nhwcì˜ ì±„ë„ìˆ˜\(c\)



{% hint style="info" %}
**ì‹¤ìŠµ ê²°**

7 layers & epoch : 3

test accuracy before training 0.1036 0 epoch & validation cost 0.09746909 sess save: 0.09746909 1 epoch & validation cost 0.05528703 sess save: 0.05528703 2 epoch & validation cost 0.057354487

test accuracy after training 0.9845
{% endhint %}

